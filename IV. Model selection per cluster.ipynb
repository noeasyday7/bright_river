{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "from tsfeatures import tsfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import Holt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure seaborn plot style: set background color and use dark grid\n",
    "sns.set(rc={'axes.facecolor':'#E6E6E6'}, style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_clustered.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/test_clustered.csv\", index_col=0)\n",
    "cluster = pd.read_csv(\"data/clustered_products.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.ds = pd.to_datetime(df_train.ds, format=\"%Y-%m-%d\")\n",
    "df_test.ds = pd.to_datetime(df_test.ds, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = df_train.cluster.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Model selection per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the median time series for each cluster\n",
    "def evaluate_models_on_median(train, test):\n",
    "    results = {}\n",
    "    \n",
    "    # # ARIMA\n",
    "    # try:\n",
    "    #     arima_model = ARIMA(train, order=(1, 1, 1)).fit()\n",
    "    #     arima_forecast = arima_model.forecast(steps=len(test))\n",
    "    #     results['ARIMA'] = mean_absolute_error(test, arima_forecast)\n",
    "    # except:\n",
    "    #     results['ARIMA'] = float('inf')\n",
    "    \n",
    "    # SARIMA\n",
    "    try:\n",
    "        sarima_model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit(disp=False)\n",
    "        sarima_forecast = sarima_model.forecast(steps=len(test))\n",
    "        results['SARIMA'] = mean_absolute_error(test, sarima_forecast)\n",
    "    except:\n",
    "        results['SARIMA'] = float('inf')\n",
    "    \n",
    "    # Exponential Smoothing\n",
    "    try:\n",
    "        es_model = ExponentialSmoothing(train, seasonal='add', seasonal_periods=12).fit()\n",
    "        es_forecast = es_model.forecast(steps=len(test))\n",
    "        results['Exponential Smoothing'] = mean_absolute_error(test, es_forecast)\n",
    "    except:\n",
    "        results['Exponential Smoothing'] = float('inf')\n",
    "\n",
    "    # Holt's Linear Trend\n",
    "    try:\n",
    "        holt_model = Holt(train).fit()\n",
    "        holt_forecast = holt_model.forecast(steps=len(test))\n",
    "        results[\"Holt's Linear Trend\"] = mean_absolute_error(test, holt_forecast)\n",
    "    except:\n",
    "        results[\"Holt's Linear Trend\"] = float('inf')\n",
    "    \n",
    "    # # Linear Regression\n",
    "    # try:\n",
    "    #     lr_model = LinearRegression()\n",
    "    #     X_train = np.arange(len(train)).reshape(-1, 1)\n",
    "    #     lr_model.fit(X_train, train)\n",
    "    #     X_test = np.arange(len(train), len(train) + len(test)).reshape(-1, 1)\n",
    "    #     lr_forecast = lr_model.predict(X_test)\n",
    "    #     results['Linear Regression'] = mean_absolute_error(test, lr_forecast)\n",
    "    # except:\n",
    "    #     results['Linear Regression'] = float('inf')\n",
    "    \n",
    "    # # XGBoost\n",
    "    # try:\n",
    "    #     xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "    #     X_train = np.arange(len(train)).reshape(-1, 1)\n",
    "    #     xgb_model.fit(X_train, train)\n",
    "    #     X_test = np.arange(len(train), len(train) + len(test)).reshape(-1, 1)\n",
    "    #     xgb_forecast = xgb_model.predict(X_test)\n",
    "    #     results['XGBoost'] = mean_absolute_error(test, xgb_forecast)\n",
    "    # except:\n",
    "    #     results['XGBoost'] = float('inf')\n",
    "    \n",
    "    # # Random Forest\n",
    "    # try:\n",
    "    #     rf_model = RandomForestRegressor(random_state=42)\n",
    "    #     X_train = np.arange(len(train)).reshape(-1, 1)\n",
    "    #     rf_model.fit(X_train, train)\n",
    "    #     X_test = np.arange(len(train), len(train) + len(test)).reshape(-1, 1)\n",
    "    #     rf_forecast = rf_model.predict(X_test)\n",
    "    #     results['Random Forest'] = mean_absolute_error(test, rf_forecast)\n",
    "    # except:\n",
    "    #     results['Random Forest'] = float('inf')\n",
    "    \n",
    "    # # LSTM\n",
    "    # try:\n",
    "    #     lstm_model = Sequential([\n",
    "    #         LSTM(50, activation='relu', input_shape=(1, 1)),\n",
    "    #         Dense(1)\n",
    "    #     ])\n",
    "    #     lstm_model.compile(optimizer='adam', loss='mae')\n",
    "    #     train_reshaped = train.reshape(-1, 1, 1)\n",
    "    #     lstm_model.fit(train_reshaped, train, epochs=10, batch_size=1, verbose=0)\n",
    "    #     test_reshaped = np.arange(len(train), len(train) + len(test)).reshape(-1, 1, 1)\n",
    "    #     lstm_forecast = lstm_model.predict(test_reshaped).flatten()\n",
    "    #     results['LSTM'] = mean_absolute_error(test, lstm_forecast)\n",
    "    # except:\n",
    "    #     results['LSTM'] = float('inf')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse dictionary\n",
    "def inverse_dict(d):\n",
    "    return {v: k for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Best Model = Exponential Smoothing (MAE = 8.35)\n",
      "Cluster 0: Best Model = Holt's Linear Trend (MAE = 22.76)\n",
      "Cluster 2: Best Model = Holt's Linear Trend (MAE = 24.90)\n"
     ]
    }
   ],
   "source": [
    "# Find the best model for each cluster\n",
    "clusters_centroid = inverse_dict(cluster[cluster[\"centroid\"] == True][\"cluster\"].to_dict())\n",
    "clusters_model ={}\n",
    "\n",
    "for c, i in clusters_centroid.items():\n",
    "    train = df_train[df_train[\"unique_id\"] == i].y\n",
    "    test = df_test[df_test[\"unique_id\"] == i].y\n",
    "\n",
    "    mae = evaluate_models_on_median(train, test)\n",
    "    best_model = min(mae, key=mae.get)\n",
    "    clusters_model[c] = best_model\n",
    "\n",
    "    print(f\"Cluster {c}: Best Model = {best_model} (MAE = {mae[best_model]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model_df = pd.DataFrame(data=clusters_model.items(), columns=[\"cluster\", \"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model_df.to_csv(\"data/clusters_model.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
