{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "from tsfeatures import tsfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mholtwinters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Holt\n",
      "\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n",
      "\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n",
      "\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import Holt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure seaborn plot style: set background color and use dark grid\n",
    "sns.set(rc={'axes.facecolor':'#E6E6E6'}, style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_results = {}\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_indices = np.where(clusters == cluster)[0]\n",
    "    cluster_series = time_series_data[cluster_indices]\n",
    "    best_model = best_model_by_cluster[cluster]\n",
    "    \n",
    "    for idx, series in enumerate(cluster_series):\n",
    "        train_series = # input train data\n",
    "        test_series = # input test data\n",
    "        \n",
    "        if best_model == 'ARIMA':\n",
    "            model = ARIMA(train_series, order=(1, 1, 1)).fit()\n",
    "            forecast = model.forecast(steps=len(test_series))\n",
    "        elif best_model == 'SARIMA':\n",
    "            model = SARIMAX(train_series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit(disp=False)\n",
    "            forecast = model.forecast(steps=len(test_series))\n",
    "        elif best_model == 'Exponential Smoothing':\n",
    "            model = ExponentialSmoothing(train_series, seasonal='add', seasonal_periods=12).fit()\n",
    "            forecast = model.forecast(steps=len(test_series))\n",
    "        elif best_model == 'Linear Regression':\n",
    "            lr_model = LinearRegression()\n",
    "            X_train = np.arange(len(train_series)).reshape(-1, 1)\n",
    "            lr_model.fit(X_train, train_series)\n",
    "            X_test = np.arange(len(train_series), len(train_series) + len(test_series)).reshape(-1, 1)\n",
    "            forecast = lr_model.predict(X_test)\n",
    "        elif best_model == 'XGBoost':\n",
    "            xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "            X_train = np.arange(len(train_series)).reshape(-1, 1)\n",
    "            xgb_model.fit(X_train, train_series)\n",
    "            X_test = np.arange(len(train_series), len(train_series) + len(test_series)).reshape(-1, 1)\n",
    "            forecast = xgb_model.predict(X_test)\n",
    "        elif best_model == 'Random Forest':\n",
    "            rf_model = RandomForestRegressor(random_state=42)\n",
    "            X_train = np.arange(len(train_series)).reshape(-1, 1)\n",
    "            rf_model.fit(X_train, train_series)\n",
    "            X_test = np.arange(len(train_series), len(train_series) + len(test_series)).reshape(-1, 1)\n",
    "            forecast"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
